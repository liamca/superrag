{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Demonstration of leveraging Azure OpenAI to improve accuracy of results through re-ranking \n",
        "# of results retrieved from an Azure AI Search service\n",
        "\n",
        "# IMPORTANT: Update config.json with your Azure OpenAI Service details"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1713273074547
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "from openai import AzureOpenAI\n",
        "import openai\n",
        "from tenacity import retry, wait_random_exponential, stop_after_attempt \n",
        "from scipy.spatial.distance import cosine  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai_temperature = 0.1\n",
        "\n",
        "#Load the configuration details for the Azure OpenAI Instance\n",
        "#Credentials should be secured using a more secure method such as Azure KeyVault\n",
        "config = json.load(open(\"config.json\"))\n",
        "\n",
        "#Azure OpenAI\n",
        "openai_embedding_api_base = config[\"openai_embedding_api_base\"]\n",
        "openai_embedding_api_key = config[\"openai_embedding_api_key\"]\n",
        "openai_embedding_api_version = config[\"openai_embedding_api_version\"]\n",
        "openai_embeddings_model = config[\"openai_embedding_model\"]\n",
        "\n",
        "openai_gpt_api_base = config[\"openai_gpt_api_base\"]\n",
        "openai_gpt_api_key = config[\"openai_gpt_api_key\"]\n",
        "openai_gpt_api_version = config[\"openai_gpt_api_version\"]\n",
        "openai_gpt_model = config[\"openai_gpt_model\"]\n",
        "\n",
        "# gets the API Key from environment variable AZURE_OPENAI_API_KEY\n",
        "embeddings_client = AzureOpenAI(\n",
        "    api_version=openai_embedding_api_version,\n",
        "    azure_endpoint=openai_embedding_api_base,\n",
        "    api_key=openai_embedding_api_key\n",
        ")\n",
        "\n",
        "gpt_client = AzureOpenAI(\n",
        "    api_version=openai_gpt_api_version,\n",
        "    azure_endpoint=openai_gpt_api_base,\n",
        "    api_key=openai_gpt_api_key\n",
        ")\n",
        "\n",
        "print ('Azure OpenAI Embeddings Base URL:', openai_embedding_api_base)\n",
        "print ('Azure OpenAI Embeddings Model:', openai_embeddings_model)\n",
        "print ('Azure OpenAI GPT Base URL:', openai_gpt_api_base)\n",
        "print ('Azure OpenAI GPT Model:', openai_gpt_model)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Azure OpenAI Embeddings Base URL: https://YOUR_SERVICE.openai.azure.com/\nAzure OpenAI Embeddings Model: text-embedding-3-large\nAzure OpenAI GPT Base URL: https://YOUR_SERVICE.openai.azure.com/\nAzure OpenAI GPT Model: gpt-4\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714141251199
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate vectors content\n",
        "max_attempts = 6\n",
        "max_backoff = 60\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(max_attempts))\n",
        "def generate_embedding(text):\n",
        "    try:\n",
        "        # text-embedding-3-small == 1536 dims\n",
        "        response = embeddings_client.embeddings.create(\n",
        "            input=text,\n",
        "            model=openai_embeddings_model\n",
        "        )\n",
        "        return json.loads(response.model_dump_json())[\"data\"][0]['embedding']\n",
        "    except Exception as ex:\n",
        "        print ('Error - Retry count:', ex)\n",
        "    return None\n",
        "\n",
        "# Determine the relevancy of text based on a question and return confidence as well as relevent text from text\n",
        "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
        "def rerank_documents(question, data):\n",
        "    system_prompt = \"\"\"\n",
        "        I am going to supply you with a set of potential answers and your goal is to determine which of them is best able to answer the question: \\n\"\"\" +  question + \"\"\"\n",
        "        Please respond in JSON format with a \"confidence\" score for each example indicating your confidence the text answers the question as well as the \"id\" of the text.  \n",
        "        Please also include a field called \"relevent_text\" which includes the text that is relevent to being able to answer the question.  \n",
        "\n",
        "        Each example will include an answer id as well as the text for the potential answer, separated by a colon.  \n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = \"\"\n",
        "    for d in data:\n",
        "        user_prompt += d[0] + \": \" + d[1] + \"\\n\"\n",
        "\n",
        "    try:\n",
        "        response = gpt_client.chat.completions.create(\n",
        "            model=openai_gpt_model, \n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt}\n",
        "            ],\n",
        "            response_format={ \"type\": \"json_object\" },\n",
        "            temperature=openai_temperature,\n",
        "            max_tokens=4096,\n",
        "            top_p=0.95,\n",
        "            frequency_penalty=0,\n",
        "            presence_penalty=0,\n",
        "            stop=None\n",
        "        )\n",
        "        json_data = json.loads(response.choices[0].message.content)\n",
        "        return json_data\n",
        "    except Exception as ex:\n",
        "        print ('Error - Retry count:', ex)\n",
        "    \n",
        "    return {}\n",
        "\n",
        "        \n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714141048183
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the Cosine Similarity of the query and answers (to understand semantics vs intent)\n",
        "question_emb = generate_embedding('Does the applicant have any significant illnesses in his medical history?')\n",
        "\n",
        "answer_1_emb = generate_embedding('Please use application form 354-01 to enter applicants medical history, significant illnesses and other symptoms.')\n",
        "answer_2_emb = generate_embedding('Mr. John Doe, a 35-year-old non-smoker, is applying for a life insurance policy. He works as an accountant and leads a low-risk lifestyle. He exercises regularly and maintains a healthy diet. His medical history reveals no significant illnesses, and his family history is also clear of any hereditary diseases. He is interested in a policy with a coverage amount of $500,000')\n",
        "\n",
        "print(\"Cosine Similarity of Question to Answer 1:\", 1 - cosine(question_emb, answer_1_emb))  \n",
        "print(\"Cosine Similarity of Question to Answer 2:\", 1 - cosine(question_emb, answer_2_emb))  \n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Cosine Similarity of Question to Answer 1: 0.5595185612023936\nCosine Similarity of Question to Answer 2: 0.39874486454438407\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714141050009
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Score the answers based on intent and retrieve relevent text\n",
        "question = \"Does the applicant have any significant illnesses in his medical history?\"\n",
        "\n",
        "data = [\n",
        "    [\"1\", \"Please use application form 354-02 to enter applicants medical history, significant illnesses and other symptoms.\"],\n",
        "    [\"2\", \"Mr. John Doe, a 35-year-old non-smoker, is applying for a life insurance policy. He works as an accountant and leads a low-risk lifestyle. He exercises regularly and maintains a healthy diet. His medical history reveals no significant illnesses, and his family history is also clear of any hereditary diseases. He is interested in a policy with a coverage amount of $500,000\"],\n",
        "]\n",
        "print(json.dumps(rerank_documents(question, data), indent=4))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{\n    \"answers\": [\n        {\n            \"id\": 1,\n            \"confidence\": 0.1,\n            \"relevent_text\": \"Please use application form 354-02 to enter applicants medical history, significant illnesses and other symptoms.\"\n        },\n        {\n            \"id\": 2,\n            \"confidence\": 0.9,\n            \"relevent_text\": \"His medical history reveals no significant illnesses, and his family history is also clear of any hereditary diseases.\"\n        }\n    ]\n}\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1714141063637
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}